{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./stsvv-clean\"\n",
    "output_folder = \"./model.zip\"\n",
    "wrong_case_folder = \"./res.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!huggingface-cli login --token=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, models\n",
    "from sentence_transformers.readers import STSDataReader\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator,BinaryClassificationEvaluator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_reader = STSDataReader(dataset_folder=data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = sts_reader.get_examples(\"train.csv\")\n",
    "eval_set = sts_reader.get_examples(\"eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Transformer(\"NlpHUST/gpt2-vietnamese\", do_lower_case=True)\n",
    "# model = models.Transformer(\"vinai/phobert-base-v2\", do_lower_case=True)\n",
    "# model = models.Transformer(\"/kaggle/working/model.zip\", do_lower_case=True)\n",
    "model.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.auto_model.resize_token_embeddings(len(model.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model = models.Pooling(model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(eval_set, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)], epochs=3,\n",
    "    evaluator=evaluator, output_path=output_folder,\n",
    "    save_best_model=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(evaluator=evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(train_set)\n",
    "print(model.evaluate(evaluator=evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = sts_reader.get_examples(\"test.csv\")\n",
    "# for example in test_set:\n",
    "#     example.label = round(example.label)\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_set, show_progress_bar=False, write_csv=True)\n",
    "print(model.evaluate(evaluator=evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "\n",
    "predictions = []\n",
    "for example in test_set:\n",
    "    sentence1 = example.texts[0]\n",
    "    sentence2 = example.texts[1]\n",
    "    label = example.label\n",
    "\n",
    "    sentence_embeddings1 = model.encode(sentence1, show_progress_bar=False)\n",
    "    sentence_embeddings2 = model.encode(sentence2, show_progress_bar=False)\n",
    "\n",
    "    cos_similarity = util.cos_sim(sentence_embeddings1, sentence_embeddings2)\n",
    "    \n",
    "    predictions.append((sentence1, sentence2, label, round(float(cos_similarity), 2)))\n",
    "\n",
    "# Identify incorrect predictions\n",
    "incorrect_predictions = []\n",
    "for example in predictions:\n",
    "    sentence1, sentence2, label, prediction = example\n",
    "    \n",
    "    temp_pred = 1 if prediction >= 0.5 else 0\n",
    "    temp_label = 1 if label >= 0.5 else 0\n",
    "    \n",
    "    if temp_pred != temp_label:\n",
    "        incorrect_predictions.append(example)\n",
    "\n",
    "print(len(incorrect_predictions)/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(incorrect_predictions, columns=['Sentence1', 'Sentence2', 'label', 'predictions'])\n",
    "results.to_csv(wrong_case_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
